model:
  vqgan:
    target: vqgan.models.vqgan.VQModel
    checkpoint_path: ./vqgan/runs/ffhq_f16_8192/vqgan_173748.pt
    params:
      codebook:
        target: vector_quantize_pytorch.VectorQuantize
        params:
          dim: 1024
          codebook_size: 8192
      encoder_decoder:
        encoder_target: vqgan.modules.encoders.encoders.MultiLayerEncoder2D
        decoder_target: vqgan.modules.decoders.decoders.MultiLayerDecoder2D
        params:
          resolution: 256
          in_channels: 3 # RGB
          out_channels: 3 # RGB
          attention_target: vqgan.modules.attention.AttnBlock
          channels: 128 # first convolution out dim
          channel_multiplier: [1, 1, 2, 2, 4] # by how much to multiply the channel for each successive layer
          z_channels: 256 # the last layer
          num_res_blocks: 2 # number of residual blocks per layer
          resolution_attention: [16]
  reformer:
    params:



training:
  save_every: 100
  sample_every: 100
  batch_size: 16
  learning_rate: 2e-5

data:
  target: utils.data.ImageLatentsDataset
  params:
    root: ./data/ffhq_f16_8192_latents/