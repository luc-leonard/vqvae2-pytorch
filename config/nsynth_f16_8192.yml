model:
  target: audio_vqgan.models.vqgan.VQModel
  params:
    dimension: 1
    codebook:
      target: vector_quantize_pytorch.VectorQuantize
      params:
        dim: 1024
        codebook_size: 8192
    encoder_decoder:
      encoder_target: audio_vqgan.modules.encoders.encoders.WaveformEncoder
      decoder_target: audio_vqgan.modules.decoders.decoders.WaveformDecoder
      params:
        samples_per_second: 16000
        in_channels: 1
        out_channels: 1
        attention_target: audio_vqgan.modules.attention.TorchAttnBlock
        channels: 128 # first convolution out dim
        channel_multiplier: [1, 1, 2, 2, 4] # by how much to multiply the channel for each successive layer
        z_channels: 256 # the last layer
        num_res_blocks: 2 # number of residual blocks per layer
        attention_layers_at: [4]

loss:
  codebook:
    factor: 1.0
  perceptual:
    target: torch.nn.MSELoss
    params:
      reduction: 'mean'
    factor: 0.0
  discriminator:
    target: audio_vqgan.models.discriminator.NLayerDiscriminator1D
    device: cuda
    params:
      ndf: 64
      input_nc: 1
      n_layers: 3
      use_actnorm: False
    factor: 0.8
    iter_start: 30000




train:
  lr: 4.5e-6
  callbacks:
    - target: audio_vqgan.training.callbacks.WaveformReconstructionTensorBoardCallback
      params:
        every: 50
    - target: audio_vqgan.training.callbacks.LossLogCallback
      params:
  save_every: 5000
  batch_size: 4


data:
  target: utils.data.SoundDataset
  params:
    data_dir: /media/lleonard/big_slow_disk/datasets/nsynth/train/nsynth-train
