model:
  target: vqgan.models.vqgan.VQModel

  params:
    dimension: 2
    codebook:
      target: vector_quantize_pytorch.VectorQuantize
      params:
        dim: 1024
        codebook_size: 8192
    encoder_decoder:
      encoder_target: vqgan.modules.encoders.encoders.MultiLayerEncoder2D
      decoder_target: vqgan.modules.decoders.decoders.MultiLayerDecoder2D
      params:
        resolution: 256
        in_channels: 3 # RGB
        out_channels: 3 # RGB
        attention_target: vqgan.modules.attention.AttnBlock
        channels: 128 # first convolution out dim
        channel_multiplier: [1, 1, 2, 2, 4] # by how much to multiply the channel for each successive layer
        z_channels: 256 # the last layer
        num_res_blocks: 2 # number of residual blocks per layer
        resolution_attention: [16]

loss:
  reconstruction:
    target: torch.nn.MSELoss
    factor: 1.0
  codebook:
    factor: 1.0
  perceptual:
    target: vqgan.modules.losses.LpipsLoss
    params:
      perceptual_model: vgg
    factor: 0.8
  discriminator:
    target: vqgan.models.discriminator.NLayerDiscriminator
    device: cuda
    params:
      ndf: 64
      n_layers: 3
      use_actnorm: False
    factor: 1.0
    iter_start: 30000




train:
  lr: 4.5e-6
  callbacks:
    - target: vqgan.training.callbacks.ImageReconstructionTensorBoardCallback
      params:
        every: 50
    - target: vqgan.training.callbacks.LossLogCallback
      params:
  save_every: 5000
  batch_size: 8


data:
  target: utils.data.MyImageFolderDataset
  params:
    data_dir: /media/lleonard/big_slow_disk/datasets/ffhq/images1024x1024/
    resize: 256
