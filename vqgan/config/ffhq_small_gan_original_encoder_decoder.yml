model:
  target: vqgan.models.vqgan.VQModel
  params:
    codebook:
      target: vector_quantize_pytorch.VectorQuantize
      params:
        dim: 512
        codebook_size: 1024
    encoder_decoder:
      encoder_target: vqgan.modules.encoders.legacy.Encoder
      decoder_target: vqgan.modules.decoders.legacy.Decoder
      params:
        resolution: 256
        in_channels: 3 # RGB
        out_channels: 3 # RGB

        channels: 128 # first convolution out dim
        channel_multiplier: [1, 2, 2, 4] # by how much to multiply the channel for each successive layer
        z_channels: 256 # the last layer
        num_res_blocks: 2 # number of residual blocks per layer
        resolution_attention: [32]

loss:
  reconstruction:
    target: torch.nn.MSELoss
    factor: 1.0
  codebook:
    factor: 1.0
  perceptual:
    target: vqgan.modules.losses.LpipsLoss
    params:
      perceptual_model: vgg
    factor: 0.8
  discriminator:
    target: vqgan.models.discriminator.NLayerDiscriminator
    device: cuda
    params:
      ndf: 64
      n_layers: 3
      use_actnorm: False
    factor: 1.0
    iter_start: 10000



train:
  lr: 4.5e-6
  callbacks:
    - target: vqgan.training.callbacks.ImageReconstructionTensorBoardCallback
      params:
        every: 100
    - target: vqgan.training.callbacks.LossLogCallback
      params:
  total_steps: 150000
  save_every: 1000
  sample_every: 100
  batch_size: 2


data:
  target: utils.data.MyImageFolderDataset
  params:
    data_dir: /media/lleonard/big_slow_disk/datasets/ffhq/images1024x1024/
    resize: [256, 256]
