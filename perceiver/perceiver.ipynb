{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from perceiver_pytorch import PerceiverIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4096, 8192])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PerceiverIO(\n",
    "    dim = 1,                    # dimension of sequence to be encoded\n",
    "    queries_dim = 3,            # dimension of decoder queries\n",
    "    logits_dim = 8192,            # dimension of final logits\n",
    "    depth = 6,                   # depth of net\n",
    "    num_latents = 256,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
    "    latent_dim = 512,            # latent dimension\n",
    "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
    "    latent_heads = 8,            # number of heads for latent self attention, 8\n",
    "    cross_dim_head = 64,         # number of dimensions per cross attention head\n",
    "    latent_dim_head = 64,        # number of dimensions per latent self attention head\n",
    "    weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
    ")\n",
    "\n",
    "seq = torch.randn(1, 64 * 64, 1)\n",
    "queries = torch.randn(1, 64 * 64, 3)\n",
    "mask = torch.ones(1, 64 * 64).bool()\n",
    "\n",
    "logits = model(seq, queries=queries, mask=mask)\n",
    "logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}